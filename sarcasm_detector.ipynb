{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "sarcasm_detector.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ycnTEpzeQogY"
      },
      "source": [
        "# Sarcasm Text Detection\n",
        "\n",
        "This notebook looks into using Python-based ML and Data Science libraries in an attempt to build a ML model capable of detecting whether sarcasm is present in a new headline.\n",
        "\n",
        "## 1. Problem Definition\n",
        "Can you identify sarcastic sentences? Can you distinguish between fake news and legitimate news?\n",
        "\n",
        "## 2. Data\n",
        "This News Headlines dataset for Sarcasm Detection is collected from two news website, TheOnion and HuffPost.\n",
        "\n",
        "Available at https://www.kaggle.com/rmisra/news-headlines-dataset-for-sarcasm-detection\n",
        "\n",
        "## 3. Evaluation\n",
        "If we can reach 95% accuracy at predicting whether or not sarcasm is present in a new headline during the proof of concept, we will pursue the project.\n",
        "\n",
        "## 4. Features\n",
        "Each record consists of three attributes:\n",
        "* `is_sarcastic`: 1 if the record is sarcastic otherwise 0\n",
        "* `headline`: the headline of the news article\n",
        "* `article_link`: link to the original news article. Useful in collecting supplementary data\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3h1xfGwVPcfi"
      },
      "source": [
        "## Code Functions\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5rlNRAkPcNJ"
      },
      "source": [
        "import zipfile\n",
        "\n",
        "def unzip_data(filename):\n",
        "  \"\"\"\n",
        "  Unzips filename into the current working directory.\n",
        "\n",
        "  Args:\n",
        "    filename (str): a filepath to a target zip folder to be unzipped.\n",
        "  \"\"\"\n",
        "  zip_ref = zipfile.ZipFile(filename, \"r\")\n",
        "  zip_ref.extractall()\n",
        "  zip_ref.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HJhDkQn8PlW8"
      },
      "source": [
        "import datetime\n",
        "import tensorflow as tf\n",
        "\n",
        "def create_tensorboard_callback(dir_name, experiment_name):\n",
        "  \"\"\"\n",
        "  Creates a TensorBoard callback instand to store log files.\n",
        "\n",
        "  Stores log files with the filepath:\n",
        "    \"dir_name/experiment_name/current_datetime/\"\n",
        "\n",
        "  Args:\n",
        "    dir_name: target directory to store TensorBoard log files\n",
        "    experiment_name: name of experiment directory (e.g. efficientnet_model_1)\n",
        "  \"\"\"\n",
        "  log_dir = dir_name + \"/\" + experiment_name + \"/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
        "  tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
        "      log_dir=log_dir\n",
        "  )\n",
        "  print(f\"Saving TensorBoard log files to: {log_dir}\")\n",
        "  return tensorboard_callback\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UvaWdOaiQNQI"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "\n",
        "  Args:\n",
        "    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n",
        "  \"\"\" \n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-8R_k9IfQREa"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_loss_curves(history):\n",
        "  \"\"\"\n",
        "  Returns separate loss curves for training and validation metrics.\n",
        "\n",
        "  Args:\n",
        "    history: TensorFlow model History object (see: https://www.tensorflow.org/api_docs/python/tf/keras/callbacks/History)\n",
        "  \"\"\" \n",
        "  loss = history.history['loss']\n",
        "  val_loss = history.history['val_loss']\n",
        "\n",
        "  accuracy = history.history['accuracy']\n",
        "  val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "  epochs = range(len(history.history['loss']))\n",
        "\n",
        "  # Plot loss\n",
        "  plt.plot(epochs, loss, label='training_loss')\n",
        "  plt.plot(epochs, val_loss, label='val_loss')\n",
        "  plt.title('Loss')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend()\n",
        "\n",
        "  # Plot accuracy\n",
        "  plt.figure()\n",
        "  plt.plot(epochs, accuracy, label='training_accuracy')\n",
        "  plt.plot(epochs, val_accuracy, label='val_accuracy')\n",
        "  plt.title('Accuracy')\n",
        "  plt.xlabel('Epochs')\n",
        "  plt.legend();\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nhAF4fI_anoG"
      },
      "source": [
        "## Visualising a text dataset"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "BrQn32aCOsMZ",
        "outputId": "0a50b27d-52ff-4fe6-ee64-d122f194bdc0"
      },
      "source": [
        "import pandas as pd\n",
        "df = pd.read_json(\"/content/drive/MyDrive/sarcasm_detector/Sarcasm_Headlines_Dataset.json\", lines=True)\n",
        "dfv2 = pd.read_json(\"/content/drive/MyDrive/sarcasm_detector/Sarcasm_Headlines_Dataset_v2.json\", lines=True)\n",
        "train_df=pd.concat([df,dfv2])\n",
        "train_df.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
              "      <td>former versace store clerk sues over secret 'b...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
              "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
              "      <td>mom starting to fear son's web series closest ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
              "      <td>boehner just wants wife to listen, not come up...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
              "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                        article_link  ... is_sarcastic\n",
              "0  https://www.huffingtonpost.com/entry/versace-b...  ...            0\n",
              "1  https://www.huffingtonpost.com/entry/roseanne-...  ...            0\n",
              "2  https://local.theonion.com/mom-starting-to-fea...  ...            1\n",
              "3  https://politics.theonion.com/boehner-just-wan...  ...            1\n",
              "4  https://www.huffingtonpost.com/entry/jk-rowlin...  ...            0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_G2XuF2ObP3G"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "ulEVNIbNcNXt",
        "outputId": "d9841659-bff9-4c28-f59e-1a8976a8d28d"
      },
      "source": [
        "# Shuffle training dataframe\n",
        "train_df_shuffled = train_df.sample(frac=1, random_state=42)\n",
        "train_df_shuffled.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>article_link</th>\n",
              "      <th>headline</th>\n",
              "      <th>is_sarcastic</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>25962</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/stephen-c...</td>\n",
              "      <td>stephen colbert reveals the back-up slogans fo...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>273</th>\n",
              "      <td>https://politics.theonion.com/hooded-members-o...</td>\n",
              "      <td>hooded members of congress drown another love ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6087</th>\n",
              "      <td>https://local.theonion.com/man-knows-he-must-r...</td>\n",
              "      <td>man knows he must ride unexpected urge to clea...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24057</th>\n",
              "      <td>https://www.theonion.com/area-family-awakes-to...</td>\n",
              "      <td>area family awakes to find michelle obama tend...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26448</th>\n",
              "      <td>https://www.huffingtonpost.com/entry/james-cor...</td>\n",
              "      <td>james corden and harry styles kiss for holiday...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                            article_link  ... is_sarcastic\n",
              "25962  https://www.huffingtonpost.com/entry/stephen-c...  ...            0\n",
              "273    https://politics.theonion.com/hooded-members-o...  ...            1\n",
              "6087   https://local.theonion.com/man-knows-he-must-r...  ...            1\n",
              "24057  https://www.theonion.com/area-family-awakes-to...  ...            1\n",
              "26448  https://www.huffingtonpost.com/entry/james-cor...  ...            0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3SIuMbi1cc-l",
        "outputId": "37d3e699-0398-47e8-ee26-d2d13103a4fa"
      },
      "source": [
        "# How many examples of each class?\n",
        "train_df.is_sarcastic.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    29970\n",
              "1    25358\n",
              "Name: is_sarcastic, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Z6d3q5wXcfm5",
        "outputId": "f44841e6-f15d-4ca4-d046-2732214fa0ce"
      },
      "source": [
        "# How many total samples?\n",
        "len(train_df)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "55328"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GtLeLRfscrv5",
        "outputId": "03f72ad5-c575-436e-e7c1-4bb487228157"
      },
      "source": [
        "# Let's visualise some random training samples\n",
        "import random\n",
        "random_index = random.randint(0, len(train_df)-5) # create random indexes not higher than the total number of samples\n",
        "for row in train_df_shuffled[[\"headline\", \"is_sarcastic\"]][random_index:random_index+5].itertuples():\n",
        "  _, headline, is_sarcastic = row\n",
        "  print(f\"Target: {is_sarcastic}\", \"(Sarcastic)\" if is_sarcastic > 0 else \"(not Sarcastic)\")\n",
        "  print(f\"headline:\\n{headline}\\n\")\n",
        "  print(\"---\\n\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Target: 1 (Sarcastic)\n",
            "headline:\n",
            "members of u2 to stare in different directions\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (Sarcastic)\n",
            "headline:\n",
            "fisher-price releases new in utero fetal activity gym\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (Sarcastic)\n",
            "headline:\n",
            "christian bale glad to be done with most humiliating experience of professional life\n",
            "\n",
            "---\n",
            "\n",
            "Target: 0 (not Sarcastic)\n",
            "headline:\n",
            "donald glover's 'this is america,' through the eyes of a jim crow historian\n",
            "\n",
            "---\n",
            "\n",
            "Target: 1 (Sarcastic)\n",
            "headline:\n",
            "family wishes dad could find healthier way to express emotions than bursting into full-blown musical number\n",
            "\n",
            "---\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bmdk45QNcvvc"
      },
      "source": [
        "## Split data into training and validation sets"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xpwhBM7-dVgz"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O1FD8k5ddYqW"
      },
      "source": [
        "# Use train_test_split to split training data into training and validation sets\n",
        "train_sentences, val_sentences, train_labels, val_labels = train_test_split(train_df_shuffled[\"headline\"].to_numpy(),\n",
        "                                                                            train_df_shuffled[\"is_sarcastic\"].to_numpy(),\n",
        "                                                                            test_size=0.1, # use 10% of training data for validation\n",
        "                                                                            random_state=42)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wlMmCyikdclc",
        "outputId": "f665b669-803c-4565-cfd9-252ae02534ff"
      },
      "source": [
        "# Check the lengths\n",
        "len(train_sentences), len(val_sentences), len(train_labels), len(val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(49795, 5533, 49795, 5533)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aKLHW4DVdhMe",
        "outputId": "37654936-5ac2-4d16-c9cd-73b374715052"
      },
      "source": [
        "# Check the first 10 samples\n",
        "train_sentences[:10], train_labels[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([\"jake tapper has one-word response to creepy kellyanne conway 'snl' sketch\",\n",
              "        'camera crew discreetly trails overweight woman for obesity segment',\n",
              "        \"bobby brown thanks fans for support during 'rough times'\",\n",
              "        'alia shawkat is feeling herself',\n",
              "        \"2012 seniors thunder into high school's parking lot like coalition forces entering baghdad\",\n",
              "        'will tax reform close the gaps?',\n",
              "        'renamed arena will always be verizon wireless amphitheater to locals',\n",
              "        'latest department of interior river count comes up one short',\n",
              "        'cnn accused of ignoring certain issues on anderson cooper 340°',\n",
              "        \"a labor day documentary: 'brothers on the line' tells the story of the reuther brothers -- founding fathers of the american middle class\"],\n",
              "       dtype=object), array([0, 1, 0, 0, 1, 0, 1, 1, 1, 0]))"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C1Vn7Wv_djPA"
      },
      "source": [
        "## Converting text into numbers\n",
        "When dealing with a text problem, one of the first things you'll have to do before you can build a model is to convert text to numbers.\n",
        "\n",
        "There are a few ways to do this, namely:\n",
        "* Tokenisation - direct mapping of token (a token could be a word or a character) to numbers.\n",
        "* Embedding - create a matrix of feature vector for each token (the size of the feature vector can be defined and this embedding can be learnt)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G9C1Tqt3dvRt"
      },
      "source": [
        "### Text Vectorization (Tokenization)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wPcEYU9yd12f"
      },
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.layers.experimental.preprocessing import TextVectorization"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZvgoUjQtd2PC",
        "outputId": "b4e462e9-374a-45fe-9b05-8f82e9257d05"
      },
      "source": [
        "# Find the average number of tokens (words) in the training tweets\n",
        "round(sum([len(i.split()) for i in train_sentences])/len(train_sentences))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "10"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4ZBFZ7V_d4q7"
      },
      "source": [
        "# Setup text vectorization variables\n",
        "max_vocab_length = 10000 # max number of words to have in our vocabulary\n",
        "max_length = 15 # max length our sequences will be (e.g. how many words from a Tweet does a model see?)\n",
        "\n",
        "text_vectorizer = TextVectorization(max_tokens=max_vocab_length,\n",
        "                                    output_mode=\"int\",\n",
        "                                    output_sequence_length=max_length)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KopGcdXMd-17"
      },
      "source": [
        "# Fit the text vectorizer to the training text\n",
        "text_vectorizer.adapt(train_sentences)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kuLTzy4geBt5",
        "outputId": "76668a05-24b0-4b50-cf20-e3c9dc9f8ed3"
      },
      "source": [
        "# Create a sample sentence and tokenise it\n",
        "sample_sentence = \"There's a flood in my street!\"\n",
        "text_vectorizer([sample_sentence])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[ 690,    7, 4435,    5,   76,  522,    0,    0,    0,    0,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7QqaNNhDeDkD",
        "outputId": "10f501af-c6cc-4b99-c4c8-04108e7df92e"
      },
      "source": [
        "# Choose a random sentence from the training dataset and tokenizer it\n",
        "random_sentence=random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "        \\n\\nVectorized version:\")\n",
        "text_vectorizer([random_sentence])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " olympic skier ashley caldwell's snooze button habit is so relatable        \n",
            "\n",
            "Vectorized version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15), dtype=int64, numpy=\n",
              "array([[1145,    1, 4277,    1, 8584, 3417, 3139,   11,  103, 9965,    0,\n",
              "           0,    0,    0,    0]])>"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3cZH4eieLOX",
        "outputId": "ded75c38-4e87-4b28-af01-73a82ca4854a"
      },
      "source": [
        "# Get the unique words in the vocabulary\n",
        "words_in_vocab = text_vectorizer.get_vocabulary() # get all of the unique words in out training data\n",
        "top_5_words = words_in_vocab[:5] # the most common words in the vocab\n",
        "bottom_5_words = words_in_vocab[-5:] # the least common words in the vocab\n",
        "print(f\"Number of words in vocab: {len(words_in_vocab)}\")\n",
        "print(f\"Most common words in vocab: {top_5_words}\")\n",
        "print(f\"Least common words in vocab: {bottom_5_words}\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of words in vocab: 10000\n",
            "Most common words in vocab: ['', '[UNK]', 'to', 'of', 'the']\n",
            "Least common words in vocab: ['puddle', 'publicists', 'pub', 'psychopath', 'proximity']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b0o-nginffxS"
      },
      "source": [
        "### Create an Embedding using an Embedding Layer\n",
        "\n",
        "The parameters we care most about for our embedding layer:\n",
        "* `input_dim` = the size of our vocabulary\n",
        "* `output_dim` = the size of the output embedding vector, for example, a value of 100 would mean each token gets represented by a vector 100 long\n",
        "* `input_length` = length of the sequences being passed to the embedding layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AId0YcfWeRIM",
        "outputId": "33814889-e570-47d4-a578-83f843964dab"
      },
      "source": [
        "from tensorflow.keras import layers\n",
        "\n",
        "embedding = layers.Embedding(input_dim=max_vocab_length, # set input shape\n",
        "                             output_dim=128, # output shape\n",
        "                             embeddings_initializer=\"uniform\",\n",
        "                             input_length=max_length # how long is each input\n",
        "                             )\n",
        "embedding"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.embeddings.Embedding at 0x7f01b0213b10>"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cPPuUNW-fieI",
        "outputId": "08c6590a-4a98-4ef5-9dab-3f53d63567aa"
      },
      "source": [
        "# Get a random sentence from the training set\n",
        "random_sentence = random.choice(train_sentences)\n",
        "print(f\"Original text:\\n {random_sentence}\\\n",
        "        \\n\\nEmbedded version:\")\n",
        "\n",
        "# Embed the random sentence (turn it into dense vectors of fixed size)\n",
        "sample_embed = embedding(text_vectorizer([random_sentence]))\n",
        "sample_embed"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Original text:\n",
            " you can train your brain to make smarter money decisions. here's how        \n",
            "\n",
            "Embedded version:\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1, 15, 128), dtype=float32, numpy=\n",
              "array([[[ 0.00230019,  0.01280196, -0.0236063 , ..., -0.00712721,\n",
              "         -0.00366957, -0.03328179],\n",
              "        [-0.04130096, -0.03505038,  0.02192307, ..., -0.03035457,\n",
              "         -0.04614954, -0.04982979],\n",
              "        [-0.02261202, -0.02314808, -0.00379343, ...,  0.02518312,\n",
              "          0.03604822,  0.04319829],\n",
              "        ...,\n",
              "        [ 0.03230062, -0.00723218,  0.02318162, ...,  0.02161166,\n",
              "         -0.01038497, -0.00698036],\n",
              "        [ 0.03230062, -0.00723218,  0.02318162, ...,  0.02161166,\n",
              "         -0.01038497, -0.00698036],\n",
              "        [ 0.03230062, -0.00723218,  0.02318162, ...,  0.02161166,\n",
              "         -0.01038497, -0.00698036]]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LAZju0E9hX3K",
        "outputId": "ba0fabf4-3521-4384-ddc9-1b262e513bbd"
      },
      "source": [
        "# Check out a single token's embedding\n",
        "sample_embed[0][0], sample_embed[0][0].shape, random_sentence"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(<tf.Tensor: shape=(128,), dtype=float32, numpy=\n",
              " array([ 0.00230019,  0.01280196, -0.0236063 ,  0.015237  ,  0.0241986 ,\n",
              "        -0.01818337,  0.01749957,  0.02511121,  0.02656781,  0.00045321,\n",
              "        -0.03353883,  0.00459538,  0.00706116, -0.03634101,  0.02882909,\n",
              "         0.00508069,  0.02609039, -0.04723314,  0.03731796, -0.02432874,\n",
              "        -0.01389412,  0.00697327,  0.02879757,  0.03890655, -0.02110914,\n",
              "         0.01151971, -0.03837763,  0.00501861, -0.0467907 , -0.00331026,\n",
              "        -0.01085683,  0.04345628, -0.02385403, -0.02440405,  0.0142838 ,\n",
              "         0.01354321, -0.02885977,  0.03549841,  0.04021123, -0.03139085,\n",
              "        -0.04660157,  0.0496047 ,  0.01035718, -0.04640141,  0.02094785,\n",
              "         0.02796812, -0.03052467, -0.0362823 , -0.00602137,  0.0315926 ,\n",
              "        -0.02291418, -0.04021698,  0.00294827,  0.03687317, -0.04889364,\n",
              "         0.00526979, -0.04934825,  0.0476395 , -0.001394  ,  0.01903539,\n",
              "         0.00699987, -0.01445577, -0.00874039, -0.04453819, -0.03293411,\n",
              "        -0.02940402,  0.0220704 ,  0.01560303,  0.01527751,  0.00983568,\n",
              "        -0.01616362,  0.00499235, -0.01257416,  0.00491822,  0.02981803,\n",
              "        -0.0249318 ,  0.02207247, -0.03049436, -0.00286615, -0.04945249,\n",
              "         0.00504301, -0.00137087,  0.02600701,  0.04634774,  0.01673419,\n",
              "        -0.04440572, -0.01715177,  0.01717168,  0.03259986, -0.02334393,\n",
              "         0.00605903, -0.0416105 ,  0.02027421, -0.00053724, -0.00987376,\n",
              "        -0.04453838,  0.02843318,  0.03077834,  0.0193979 ,  0.02203716,\n",
              "         0.00723668,  0.03650023, -0.01181757, -0.03443732, -0.01545367,\n",
              "        -0.00925731,  0.04811648, -0.02076929, -0.01078396, -0.03854905,\n",
              "        -0.00481144, -0.01906976,  0.03102365, -0.03705697, -0.04602851,\n",
              "         0.0014007 , -0.02433056,  0.02515078,  0.04331187,  0.0010566 ,\n",
              "         0.02944267,  0.03760273, -0.01919153, -0.01092947, -0.04809964,\n",
              "        -0.00712721, -0.00366957, -0.03328179], dtype=float32)>,\n",
              " TensorShape([128]),\n",
              " \"you can train your brain to make smarter money decisions. here's how\")"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6abbYYM5h5WR"
      },
      "source": [
        "### Model 0: Getting a baseline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JGnEskJ2hyWv",
        "outputId": "ffd8a11d-4d96-48bd-e181-0a29b5a12b76"
      },
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.pipeline import Pipeline\n",
        "\n",
        "# Create tokenization and modelling pipeline\n",
        "model_0 = Pipeline([\n",
        "                    (\"tfidf\", TfidfVectorizer()), # convert words to numbers using tfidf\n",
        "                    (\"clf\", MultinomialNB()) # model the text\n",
        "])\n",
        "\n",
        "# Fit the pipeline to the training data\n",
        "model_0.fit(train_sentences, train_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(memory=None,\n",
              "         steps=[('tfidf',\n",
              "                 TfidfVectorizer(analyzer='word', binary=False,\n",
              "                                 decode_error='strict',\n",
              "                                 dtype=<class 'numpy.float64'>,\n",
              "                                 encoding='utf-8', input='content',\n",
              "                                 lowercase=True, max_df=1.0, max_features=None,\n",
              "                                 min_df=1, ngram_range=(1, 1), norm='l2',\n",
              "                                 preprocessor=None, smooth_idf=True,\n",
              "                                 stop_words=None, strip_accents=None,\n",
              "                                 sublinear_tf=False,\n",
              "                                 token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
              "                                 tokenizer=None, use_idf=True,\n",
              "                                 vocabulary=None)),\n",
              "                ('clf',\n",
              "                 MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True))],\n",
              "         verbose=False)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rPq1SJXh8cp",
        "outputId": "70a6b9ff-a2c3-4557-e0c7-4e6b54aa659a"
      },
      "source": [
        "# Evaluate our baseline model\n",
        "baseline_score = model_0.score(val_sentences, val_labels)\n",
        "print(f\"Our baseline model achieves an accuracy of: {baseline_score*100:.2f}%\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Our baseline model achieves an accuracy of: 89.19%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WGvza19Dh_Z3",
        "outputId": "83099893-7c9f-40ca-d583-1960e53eafba"
      },
      "source": [
        "train_df.is_sarcastic.value_counts()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    29970\n",
              "1    25358\n",
              "Name: is_sarcastic, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p6nJ53utiBWT",
        "outputId": "532b804a-9e92-49ab-eedf-b9b07bf0452b"
      },
      "source": [
        "# Make predictions\n",
        "baseline_preds = model_0.predict(val_sentences)\n",
        "baseline_preds[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0])"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3-cEATdMiFd1"
      },
      "source": [
        "# Function to evalaute: accuracy, precision, recall, F1-score\n",
        "from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n",
        "\n",
        "def calculate_results(y_true, y_pred):\n",
        "  \"\"\"\n",
        "  Calculates model accuracy, precision, recall and f1 score of a binary classification model.\n",
        "\n",
        "  Args:\n",
        "  ----\n",
        "  y_true = true labels in the form of a 1D array\n",
        "  y_pred = predicted label in the form of a 1D array\n",
        "\n",
        "  Returns a dictionary of accuracy, precision, recall and f1-score between y_true and y_pred.\n",
        "  \"\"\"\n",
        "  # Calculate model accuracy\n",
        "  model_accuracy = accuracy_score(y_true, y_pred) * 100 # get accuracy score in percentage value\n",
        "  # Calculate model precision, recall and f1 score using \"weighted\" avergage\n",
        "  model_precision, model_recall, model_f1, _ = precision_recall_fscore_support(y_true, y_pred, average=\"weighted\")\n",
        "  # Create a dictionary of model results\n",
        "  model_results = {\"accuracy\": model_accuracy,\n",
        "                   \"precision\": model_precision,\n",
        "                   \"recall\": model_recall,\n",
        "                   \"f1\": model_f1}\n",
        "  return model_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XyJ15FndienF",
        "outputId": "673a3798-f558-4757-9cf0-e1ef7f19f0ed"
      },
      "source": [
        "# Get baseline results\n",
        "baseline_results = calculate_results(y_true=val_labels,\n",
        "                                     y_pred=baseline_preds)\n",
        "baseline_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 89.19212000722935,\n",
              " 'f1': 0.891278369920902,\n",
              " 'precision': 0.8941406914111836,\n",
              " 'recall': 0.8919212000722935}"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IGa52PA5ijHZ"
      },
      "source": [
        "### Model 1: A simple dense model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZVecCXsixGK"
      },
      "source": [
        "# Create a tensorboard callback (need to create a new one for each model)\n",
        "# from helper_functions import create_tensorboard_callback\n",
        "\n",
        "# Create a directory to save TensorBoard logs\n",
        "SAVE_DIR = \"model_logs\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "I0NtcYVJigXM"
      },
      "source": [
        "# Build model with the Functional API\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string) # inputs are 1-dimensional strings\n",
        "x = text_vectorizer(inputs) # turn the input text into numbers\n",
        "x = embedding(x) # create an embedding of the numberized inputs\n",
        "x = layers.GlobalAveragePooling1D()(x) # condense the feature vector for each token to one vector\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x) # Create the output layer, want binary outputs so use sigmoid activation function\n",
        "model_1 = tf.keras.Model(inputs, outputs, name=\"model_1_dense\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZubUDd_6i1Ru",
        "outputId": "1cb6c9f4-4ece-4912-b2a5-8f4c5acde1a6"
      },
      "source": [
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nKh59pri2wS"
      },
      "source": [
        "# Compile model\n",
        "model_1.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zj6nwxKEi4tN",
        "outputId": "2eadfccd-b83d-4de0-b4e2-0e8fdf64fc91"
      },
      "source": [
        "# Fit the model\n",
        "model_1_history = model_1.fit(x=train_sentences,\n",
        "                              y=train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(dir_name=SAVE_DIR,\n",
        "                                                                     experiment_name=\"model_1_dense\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_1_dense/20210909-064122\n",
            "Epoch 1/5\n",
            "1557/1557 [==============================] - 15s 8ms/step - loss: 0.3830 - accuracy: 0.8384 - val_loss: 0.2821 - val_accuracy: 0.8823\n",
            "Epoch 2/5\n",
            "1557/1557 [==============================] - 11s 7ms/step - loss: 0.2165 - accuracy: 0.9174 - val_loss: 0.2522 - val_accuracy: 0.8948\n",
            "Epoch 3/5\n",
            "1557/1557 [==============================] - 11s 7ms/step - loss: 0.1685 - accuracy: 0.9367 - val_loss: 0.2465 - val_accuracy: 0.9058\n",
            "Epoch 4/5\n",
            "1557/1557 [==============================] - 11s 7ms/step - loss: 0.1412 - accuracy: 0.9487 - val_loss: 0.2524 - val_accuracy: 0.9118\n",
            "Epoch 5/5\n",
            "1557/1557 [==============================] - 11s 7ms/step - loss: 0.1237 - accuracy: 0.9562 - val_loss: 0.2557 - val_accuracy: 0.9174\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uWxPOqLhi58w",
        "outputId": "d7938f49-a988-476d-d7c7-277628bd114e"
      },
      "source": [
        "# Check the results\n",
        "model_1.evaluate(val_sentences, val_labels)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "173/173 [==============================] - 1s 4ms/step - loss: 0.2557 - accuracy: 0.9174\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2557174265384674, 0.9174046516418457]"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0GU6vTasi9_J",
        "outputId": "6379786f-e1e0-4211-9b00-c11ae735986e"
      },
      "source": [
        "# Make some predictions and evaluate those\n",
        "model_1_pred_probs = model_1.predict(val_sentences)\n",
        "model_1_pred_probs.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(5533, 1)"
            ]
          },
          "metadata": {},
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2yfhuy4Yi_6O",
        "outputId": "e8313f15-916b-44ad-9552-95d0efe5036b"
      },
      "source": [
        "# Look at the first 10 predictions\n",
        "model_1_pred_probs[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.97609216], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EFLrjdBljDDa",
        "outputId": "d0ca5d10-164b-45e2-d279-bb73e8e5491f"
      },
      "source": [
        "# Convert model prediction probabilities to label format\n",
        "model_1_preds = tf.squeeze(tf.round(model_1_pred_probs))\n",
        "model_1_preds[:20]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(20,), dtype=float32, numpy=\n",
              "array([1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 1., 1., 0., 0., 0., 1., 1.,\n",
              "       0., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "28AQHrGqjjk8",
        "outputId": "59c0566b-adb5-49be-ba4c-0b5e65c64a5e"
      },
      "source": [
        "# Calculate our model_1 results\n",
        "model_1_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_1_preds)\n",
        "model_1_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 91.74046629315019,\n",
              " 'f1': 0.9175193285751525,\n",
              " 'precision': 0.9183473332160497,\n",
              " 'recall': 0.9174046629315019}"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3xN1ExM_jkt4",
        "outputId": "17bfc4f5-d384-4c62-d92e-2dae79a0e994"
      },
      "source": [
        "baseline_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 89.19212000722935,\n",
              " 'f1': 0.891278369920902,\n",
              " 'precision': 0.8941406914111836,\n",
              " 'recall': 0.8919212000722935}"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uIxylPWujl9I"
      },
      "source": [
        "## Visualizing learnt embeddings"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-Jenowb9jtsa",
        "outputId": "f683218c-2f3e-4f1f-fe60-587e15f40b76"
      },
      "source": [
        "# Get the vocabulary from the text vectorization layer\n",
        "words_in_vocab = text_vectorizer.get_vocabulary()\n",
        "len(words_in_vocab), words_in_vocab[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(10000, ['', '[UNK]', 'to', 'of', 'the', 'in', 'for', 'a', 'on', 'and'])"
            ]
          },
          "metadata": {},
          "execution_count": 46
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2Gqr-iAAjtp4",
        "outputId": "957a5ff6-bd37-4d2d-8e76-c50c91c356d2"
      },
      "source": [
        "# Model 1 summary\n",
        "model_1.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_1_dense\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_1 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "global_average_pooling1d (Gl (None, 128)               0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,280,129\n",
            "Trainable params: 1,280,129\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EMHBXfzzjtnS"
      },
      "source": [
        "# # Get the weight matrix of embedding layer\n",
        "# # (these are the numerical representations of each token in out training data, which have been learnt for ~5 epochs)\n",
        "# embed_weights = model_1.get_layer(\"embedding\").get_weights()[0]\n",
        "# print(embed_weights.shape) # same size as vocab size and embedding dim (output_dim of our embedding layer)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qngjblacjtkU"
      },
      "source": [
        "## Recurrent Neural Networks (RNN's)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ga-63_N9jth0"
      },
      "source": [
        "### Model 2: LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqAwV_Szj87o"
      },
      "source": [
        "# Create an LSTM model\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# print(x.shape)\n",
        "x = layers.LSTM(units=64, return_sequences=True)(x) # when you're stacking RNN cells together, you need set to return_sequences=True\n",
        "# print(x.shape)\n",
        "x = layers.LSTM(64)(x)\n",
        "# print(x.shape)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "# print(x.shape)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_2 = tf.keras.Model(inputs, outputs, name=\"model_2_LSTM\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bTcTXDKjj85H",
        "outputId": "f47695bf-0dc5-4bb7-b30e-23b64b1dba0f"
      },
      "source": [
        "# Get a summary\n",
        "model_2.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2_LSTM\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_2 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "lstm (LSTM)                  (None, 15, 64)            49408     \n",
            "_________________________________________________________________\n",
            "lstm_1 (LSTM)                (None, 64)                33024     \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,366,657\n",
            "Trainable params: 1,366,657\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UCwkkJBzj82g"
      },
      "source": [
        "# Compile the model\n",
        "model_2.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fVDNeJSSjtfE",
        "outputId": "8999eac0-7528-4be7-8f91-57c91fc7105a"
      },
      "source": [
        "# Fit the model\n",
        "model_2_history = model_2.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_2_LSTM\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_2_LSTM/20210909-064248\n",
            "Epoch 1/5\n",
            "1557/1557 [==============================] - 32s 17ms/step - loss: 0.1218 - accuracy: 0.9582 - val_loss: 0.2303 - val_accuracy: 0.9212\n",
            "Epoch 2/5\n",
            "1557/1557 [==============================] - 25s 16ms/step - loss: 0.0888 - accuracy: 0.9690 - val_loss: 0.1887 - val_accuracy: 0.9353\n",
            "Epoch 3/5\n",
            "1557/1557 [==============================] - 25s 16ms/step - loss: 0.0525 - accuracy: 0.9813 - val_loss: 0.1770 - val_accuracy: 0.9539\n",
            "Epoch 4/5\n",
            "1557/1557 [==============================] - 25s 16ms/step - loss: 0.0283 - accuracy: 0.9898 - val_loss: 0.1684 - val_accuracy: 0.9655\n",
            "Epoch 5/5\n",
            "1557/1557 [==============================] - 24s 16ms/step - loss: 0.0161 - accuracy: 0.9946 - val_loss: 0.1959 - val_accuracy: 0.9704\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "x0rk7wQNjtcR",
        "outputId": "519a83f6-91ac-408e-c6f6-94a23fff8300"
      },
      "source": [
        "# Make predictions with LSTM model\n",
        "model_2_pred_probs = model_2.predict(val_sentences)\n",
        "model_2_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.99656200e-01],\n",
              "       [1.01237163e-01],\n",
              "       [9.99981403e-01],\n",
              "       [9.99966860e-01],\n",
              "       [5.71758173e-05],\n",
              "       [3.48000904e-04],\n",
              "       [9.68556269e-05],\n",
              "       [1.15011106e-04],\n",
              "       [1.53459492e-04],\n",
              "       [6.25435205e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hHjcOZd7kGZl",
        "outputId": "2711d02e-f4bf-472f-ff3a-bd547b1086a0"
      },
      "source": [
        "# Convert model 2 prebs probs to labels\n",
        "model_2_preds = tf.squeeze(tf.round(model_2_pred_probs))\n",
        "model_2_preds"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(5533,), dtype=float32, numpy=array([1., 0., 1., ..., 1., 1., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MD9dlgn-kGXH",
        "outputId": "a8fb985c-c958-42b3-9834-cba84a38640f"
      },
      "source": [
        "# Calculate model 2 results\n",
        "model_2_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_2_preds)\n",
        "model_2_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 97.03596602204952,\n",
              " 'f1': 0.9703829707582654,\n",
              " 'precision': 0.9705919848061932,\n",
              " 'recall': 0.9703596602204952}"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "azymXd2UkGUf"
      },
      "source": [
        "### Model 3: GRU\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NM99tHJakGSJ"
      },
      "source": [
        "# Build an RNN using the GRU cell\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "# x = layers.GRU(64)(x)\n",
        "x = layers.GRU(64, return_sequences=True)(x) # if you want to stack layers on top of each other, you need to return_sequences=True\n",
        "x = layers.LSTM(64, return_sequences=True)(x)\n",
        "x = layers.GRU(64)(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_3 = tf.keras.Model(inputs, outputs, name=\"model_3_GRU\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XuoH2_pkGQB",
        "outputId": "4ed54c18-bb76-456a-dec6-2577b4275e59"
      },
      "source": [
        "model_3.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_3_GRU\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_3 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "gru (GRU)                    (None, 15, 64)            37248     \n",
            "_________________________________________________________________\n",
            "lstm_2 (LSTM)                (None, 15, 64)            33024     \n",
            "_________________________________________________________________\n",
            "gru_1 (GRU)                  (None, 64)                24960     \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_4 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,379,457\n",
            "Trainable params: 1,379,457\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L5XHw0UukGNP"
      },
      "source": [
        "# Compile the model\n",
        "model_3.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HQFp717ckGKV",
        "outputId": "1431c7c9-90e0-46d4-ad67-a4a4ae7f9ce3"
      },
      "source": [
        "# Fit the model\n",
        "model_3_history = model_3.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_3_GRU\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_3_GRU/20210909-064501\n",
            "Epoch 1/5\n",
            "1557/1557 [==============================] - 39s 22ms/step - loss: 0.0524 - accuracy: 0.9834 - val_loss: 0.1498 - val_accuracy: 0.9702\n",
            "Epoch 2/5\n",
            "1557/1557 [==============================] - 31s 20ms/step - loss: 0.0168 - accuracy: 0.9947 - val_loss: 0.1724 - val_accuracy: 0.9727\n",
            "Epoch 3/5\n",
            "1557/1557 [==============================] - 32s 20ms/step - loss: 0.0133 - accuracy: 0.9957 - val_loss: 0.1695 - val_accuracy: 0.9731\n",
            "Epoch 4/5\n",
            "1557/1557 [==============================] - 32s 20ms/step - loss: 0.0100 - accuracy: 0.9966 - val_loss: 0.1836 - val_accuracy: 0.9704\n",
            "Epoch 5/5\n",
            "1557/1557 [==============================] - 31s 20ms/step - loss: 0.0080 - accuracy: 0.9976 - val_loss: 0.1620 - val_accuracy: 0.9705\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vlnqiN-HlLQl",
        "outputId": "7887b4d2-496d-48e4-98c9-78081f90da96"
      },
      "source": [
        "# Make some predictions with our GRU model\n",
        "model_3_pred_probs = model_3.predict(val_sentences)\n",
        "model_3_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9747890e-01],\n",
              "       [1.5772554e-03],\n",
              "       [9.9956292e-01],\n",
              "       [9.9965203e-01],\n",
              "       [3.5574049e-04],\n",
              "       [4.1271903e-04],\n",
              "       [1.9433911e-04],\n",
              "       [2.0655320e-04],\n",
              "       [2.7617658e-04],\n",
              "       [1.7434821e-04]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y5gAwrATlN8J",
        "outputId": "089a6db2-c5a6-4c30-e6b6-856277ffccd9"
      },
      "source": [
        "# Convert model 3 pred probs to labels\n",
        "model_3_preds = tf.squeeze(tf.round(model_3_pred_probs))\n",
        "model_3_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 0., 1., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iYQwPwo3lOus",
        "outputId": "88f9cd36-2e4f-4bc1-f1b4-81a8fa6f287c"
      },
      "source": [
        "# Calculate model 3 results\n",
        "# val_labels.shape, model_3_preds.shape\n",
        "model_3_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_3_preds)\n",
        "model_3_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 97.05403939996386,\n",
              " 'f1': 0.9705308769452503,\n",
              " 'precision': 0.9705444525185639,\n",
              " 'recall': 0.9705403939996385}"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YgP1fPKRlQ4J"
      },
      "source": [
        "### Model 4: Bidirectional RNN\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gXFQODCpla_X",
        "outputId": "61850369-81a0-480c-e48f-db2fe8148ba3"
      },
      "source": [
        "# Build a bidirectional RNN in TensorFlow\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=\"string\")\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Bidirectional(layers.LSTM(64, return_sequences=True))(x)\n",
        "print(x.shape)\n",
        "x = layers.Bidirectional(layers.LSTM(64))(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_4 = tf.keras.Model(inputs, outputs, name=\"model_4_bidirectional\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(None, 15, 128)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vJk3_jyQla8K",
        "outputId": "98b05f23-8136-44ff-9d11-70805d4162f6"
      },
      "source": [
        "# Get a summary\n",
        "model_4.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_4_bidirectional\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_4 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "bidirectional (Bidirectional (None, 15, 128)           98816     \n",
            "_________________________________________________________________\n",
            "bidirectional_1 (Bidirection (None, 128)               98816     \n",
            "_________________________________________________________________\n",
            "dense_5 (Dense)              (None, 1)                 129       \n",
            "=================================================================\n",
            "Total params: 1,477,761\n",
            "Trainable params: 1,477,761\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rw-qDXK-la26"
      },
      "source": [
        "# Compile model\n",
        "model_4.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i_HdRGgblaxr",
        "outputId": "e7104f35-8aca-427c-a72a-8bc297613de8"
      },
      "source": [
        "# Fit the model\n",
        "model_4_history = model_4.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"model_4_bidirectional\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/model_4_bidirectional/20210909-064750\n",
            "Epoch 1/5\n",
            "1557/1557 [==============================] - 50s 27ms/step - loss: 0.0329 - accuracy: 0.9891 - val_loss: 0.1645 - val_accuracy: 0.9733\n",
            "Epoch 2/5\n",
            "1557/1557 [==============================] - 40s 26ms/step - loss: 0.0074 - accuracy: 0.9976 - val_loss: 0.1864 - val_accuracy: 0.9731\n",
            "Epoch 3/5\n",
            "1557/1557 [==============================] - 41s 26ms/step - loss: 0.0053 - accuracy: 0.9984 - val_loss: 0.2087 - val_accuracy: 0.9745\n",
            "Epoch 4/5\n",
            "1557/1557 [==============================] - 40s 26ms/step - loss: 0.0048 - accuracy: 0.9985 - val_loss: 0.1944 - val_accuracy: 0.9734\n",
            "Epoch 5/5\n",
            "1557/1557 [==============================] - 41s 26ms/step - loss: 0.0042 - accuracy: 0.9987 - val_loss: 0.1953 - val_accuracy: 0.9742\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKrqH3-1ll8L",
        "outputId": "933d7469-4fdd-47da-a744-35bb5c41a7a3"
      },
      "source": [
        "# Make predictions with our bidirectional model\n",
        "model_4_pred_probs = model_4.predict(val_sentences)\n",
        "model_4_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[9.9998176e-01],\n",
              "       [4.9553658e-03],\n",
              "       [9.9992394e-01],\n",
              "       [9.9999058e-01],\n",
              "       [6.0980354e-05],\n",
              "       [5.9336911e-05],\n",
              "       [1.0379659e-04],\n",
              "       [4.2167876e-04],\n",
              "       [3.4216275e-05],\n",
              "       [3.1179305e-05]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6aMDzSIPlmTm",
        "outputId": "a6ba001e-7791-4155-87eb-ad32bb1a8cfc"
      },
      "source": [
        "# Convert pred probs to pred labels\n",
        "model_4_preds = tf.squeeze(tf.round(model_4_pred_probs))\n",
        "model_4_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 0., 1., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AIf3vgOblnzA",
        "outputId": "84df71c0-d040-44f3-bae1-67a33263e592"
      },
      "source": [
        "# Calculate the results of our bidirectional model\n",
        "model_4_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_4_preds)\n",
        "model_4_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 97.4155069582505,\n",
              " 'f1': 0.9741588064517412,\n",
              " 'precision': 0.9741677350242788,\n",
              " 'recall': 0.974155069582505}"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q6llpcs7lpL7"
      },
      "source": [
        "### Model 5: Conv1D\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vv9P7P_mlzzA",
        "outputId": "4afd99e2-d4bb-4bee-afa4-e4eeb4a468cf"
      },
      "source": [
        "# Test out our embedding layer, Conv1D layer and max pooling\n",
        "from tensorflow.keras import layers\n",
        "embedding_test = embedding(text_vectorizer([\"This is a test sentence\"])) # turn target sequence into embedding\n",
        "conv_1d = layers.Conv1D(filters=64,\n",
        "                        kernel_size=5, # this is also referred to as an ngram of 5 (meaning it looks at 5 words at a time)\n",
        "                        strides=1, # default\n",
        "                        activation=\"relu\",\n",
        "                        padding=\"valid\") # default = \"valid\", the output is smaller than the input shape, \"same\" means output is same shape as input\n",
        "conv_1d_output = conv_1d(embedding_test) # pass test embedding through conv1d layer\n",
        "max_pool = layers.GlobalMaxPool1D()\n",
        "max_pool_output = max_pool(conv_1d_output) # equivalent to \"get the most important feature\" or \"get the feature with the highest value\"\n",
        "\n",
        "embedding_test.shape, conv_1d_output.shape, max_pool_output.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(TensorShape([1, 15, 128]), TensorShape([1, 11, 64]), TensorShape([1, 64]))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IzTtnbdll0HM",
        "outputId": "30f42871-6547-42bb-fda0-042065d2781a"
      },
      "source": [
        "# Create 1-dimensional convolutional layer to model sequences\n",
        "from tensorflow.keras import layers\n",
        "inputs = layers.Input(shape=(1,), dtype=tf.string)\n",
        "x = text_vectorizer(inputs)\n",
        "x = embedding(x)\n",
        "x = layers.Conv1D(filters=64, kernel_size=5, strides=1, activation=\"relu\", padding=\"valid\")(x)\n",
        "x = layers.GlobalMaxPool1D()(x)\n",
        "x = layers.Dense(64, activation=\"relu\")(x)\n",
        "outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n",
        "model_5 = tf.keras.Model(inputs, outputs, name=\"model_5_Conv1D\")\n",
        "\n",
        "# Compile Conv1D\n",
        "model_5.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary of our Conv1D model\n",
        "model_5.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_5_Conv1D\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "input_5 (InputLayer)         [(None, 1)]               0         \n",
            "_________________________________________________________________\n",
            "text_vectorization (TextVect (None, 15)                0         \n",
            "_________________________________________________________________\n",
            "embedding (Embedding)        (None, 15, 128)           1280000   \n",
            "_________________________________________________________________\n",
            "conv1d_1 (Conv1D)            (None, 11, 64)            41024     \n",
            "_________________________________________________________________\n",
            "global_max_pooling1d_1 (Glob (None, 64)                0         \n",
            "_________________________________________________________________\n",
            "dense_6 (Dense)              (None, 64)                4160      \n",
            "_________________________________________________________________\n",
            "dense_7 (Dense)              (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 1,325,249\n",
            "Trainable params: 1,325,249\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0mRbcxBol2WR",
        "outputId": "a893115a-4276-4e44-ce06-dff38719a960"
      },
      "source": [
        "# Fit the model\n",
        "model_5_history = model_5.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"Conv1D\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/Conv1D/20210909-065245\n",
            "Epoch 1/5\n",
            "1557/1557 [==============================] - 16s 9ms/step - loss: 0.0729 - accuracy: 0.9737 - val_loss: 0.2023 - val_accuracy: 0.9620\n",
            "Epoch 2/5\n",
            "1557/1557 [==============================] - 13s 8ms/step - loss: 0.0131 - accuracy: 0.9954 - val_loss: 0.2322 - val_accuracy: 0.9693\n",
            "Epoch 3/5\n",
            "1557/1557 [==============================] - 13s 8ms/step - loss: 0.0039 - accuracy: 0.9988 - val_loss: 0.3586 - val_accuracy: 0.9682\n",
            "Epoch 4/5\n",
            "1557/1557 [==============================] - 13s 8ms/step - loss: 0.0049 - accuracy: 0.9984 - val_loss: 0.3153 - val_accuracy: 0.9648\n",
            "Epoch 5/5\n",
            "1557/1557 [==============================] - 13s 8ms/step - loss: 0.0033 - accuracy: 0.9988 - val_loss: 0.4307 - val_accuracy: 0.9707\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JIteolp7l5CE",
        "outputId": "79850707-0953-4a32-a311-6eefbe34113e"
      },
      "source": [
        "# Make some predictions with our Conv1D model\n",
        "model_5_pred_probs = model_5.predict(val_sentences)\n",
        "model_5_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[1.0000000e+00],\n",
              "       [2.6676815e-07],\n",
              "       [1.0000000e+00],\n",
              "       [9.9999988e-01],\n",
              "       [4.5474920e-15],\n",
              "       [1.8511326e-10],\n",
              "       [1.0376018e-09],\n",
              "       [1.1967240e-16],\n",
              "       [4.3092176e-11],\n",
              "       [1.1941688e-11]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 73
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYKq45fXl6xA",
        "outputId": "41395a32-3fb2-4b7e-c80e-0daf7a4787b8"
      },
      "source": [
        "# Convert model_5 pred probs to labels\n",
        "model_5_preds = tf.squeeze(tf.round(model_5_pred_probs))\n",
        "model_5_preds[:10]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(10,), dtype=float32, numpy=array([1., 0., 1., 1., 0., 0., 0., 0., 0., 0.], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MdAaI_6Dl8yQ",
        "outputId": "571c751f-41aa-4e3d-9df5-fe00ad80b95d"
      },
      "source": [
        "# Evaluate model 5 predictions\n",
        "model_5_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_5_preds)\n",
        "model_5_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 97.07211277787819,\n",
              " 'f1': 0.9707026047652578,\n",
              " 'precision': 0.9707670996534621,\n",
              " 'recall': 0.9707211277787818}"
            ]
          },
          "metadata": {},
          "execution_count": 75
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fXHIR4bBmAgD"
      },
      "source": [
        "### Model 6: TensorFlow Hub Pretrained Sentence Encoder"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OCQyO6s8l-n7",
        "outputId": "60624492-4e38-4dd7-f51a-a2bbb172e0ed"
      },
      "source": [
        "import tensorflow_hub as hub\n",
        "embed = hub.load(\"https://tfhub.dev/google/universal-sentence-encoder/4\")\n",
        "embed_samples = embed([sample_sentence,\n",
        "                       \"When you call the universal sentence encoder on a sentence, it turns it into numbers.\"])\n",
        "print(embed_samples[0][:50])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[-0.01157024  0.0248591   0.0287805  -0.01271502  0.03971543  0.08827759\n",
            "  0.02680986  0.05589837 -0.01068731 -0.0059729   0.00639324 -0.01819523\n",
            "  0.00030817  0.09105891  0.05874644 -0.03180627  0.01512476 -0.05162928\n",
            "  0.00991369 -0.06865346 -0.04209306  0.0267898   0.03011008  0.00321069\n",
            " -0.00337969 -0.04787359  0.02266718 -0.00985924 -0.04063614 -0.01292095\n",
            " -0.04666384  0.056303   -0.03949255  0.00517685  0.02495828 -0.07014439\n",
            "  0.02871508  0.04947682 -0.00633971 -0.08960191  0.02807117 -0.00808362\n",
            " -0.01360601  0.05998649 -0.10361786 -0.05195372  0.00232955 -0.02332528\n",
            " -0.03758105  0.0332773 ], shape=(50,), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aLohQiHnmEur",
        "outputId": "2a0f11a3-24f2-4cb7-c7d2-c6a5fafb9687"
      },
      "source": [
        "embed_samples"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(2, 512), dtype=float32, numpy=\n",
              "array([[-0.01157024,  0.0248591 ,  0.0287805 , ..., -0.00186124,\n",
              "         0.02315823, -0.01485021],\n",
              "       [ 0.03596688, -0.08579469, -0.01152742, ..., -0.03414334,\n",
              "         0.02816023, -0.00878946]], dtype=float32)>"
            ]
          },
          "metadata": {},
          "execution_count": 77
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eZUsA2qMmGmJ"
      },
      "source": [
        "# Create a Keras layer using the USE pretrained layer from tensorflow hub\n",
        "sentence_encoder_layer = hub.KerasLayer(\"https://tfhub.dev/google/universal-sentence-encoder/4\",\n",
        "                                        input_shape=[],\n",
        "                                        dtype=tf.string,\n",
        "                                        trainable=False,\n",
        "                                        name=\"USE\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8f7k1PlgmH4M",
        "outputId": "cecbf1a3-8ddc-4ea7-87b1-9f40d44c5707"
      },
      "source": [
        "# Create model using the Sequential API\n",
        "model_6 = tf.keras.Sequential([\n",
        "  sentence_encoder_layer,\n",
        "  layers.Dense(64, activation=\"relu\"),\n",
        "  layers.Dense(1, activation=\"sigmoid\", name=\"output_layer\")\n",
        "], name=\"model_6_USE\")\n",
        "\n",
        "# Compile\n",
        "model_6.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "model_6.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ENeHz03YmJhe",
        "outputId": "69034ab4-e92e-412b-c330-8df569796337"
      },
      "source": [
        "# Train a classifier on top of USE pretrained embeddings\n",
        "model_6_history = model_6.fit(train_sentences,\n",
        "                              train_labels,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder/20210909-065416\n",
            "Epoch 1/5\n",
            "1557/1557 [==============================] - 37s 22ms/step - loss: 0.4552 - accuracy: 0.7836 - val_loss: 0.4242 - val_accuracy: 0.8014\n",
            "Epoch 2/5\n",
            "1557/1557 [==============================] - 32s 20ms/step - loss: 0.3974 - accuracy: 0.8158 - val_loss: 0.3975 - val_accuracy: 0.8171\n",
            "Epoch 3/5\n",
            "1557/1557 [==============================] - 31s 20ms/step - loss: 0.3630 - accuracy: 0.8363 - val_loss: 0.3714 - val_accuracy: 0.8341\n",
            "Epoch 4/5\n",
            "1557/1557 [==============================] - 32s 20ms/step - loss: 0.3319 - accuracy: 0.8540 - val_loss: 0.3496 - val_accuracy: 0.8473\n",
            "Epoch 5/5\n",
            "1557/1557 [==============================] - 34s 22ms/step - loss: 0.3063 - accuracy: 0.8688 - val_loss: 0.3326 - val_accuracy: 0.8561\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sbvx-DZvmL7U"
      },
      "source": [
        "# Make predictions with USE TF Hub Model\n",
        "model_6_pred_probs = model_6.predict(val_sentences)\n",
        "model_6_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9r4huQqPmNNa"
      },
      "source": [
        "# Convert prediction probabilities to labels\n",
        "model_6_preds = tf.squeeze(tf.round(model_6_pred_probs))\n",
        "model_6_preds[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E2Aw_bUPmO5S",
        "outputId": "2b401607-8734-448b-818a-6d6e5fb8789e"
      },
      "source": [
        "# Calculate model 6 performance metrics\n",
        "model_6_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_6_preds)\n",
        "model_6_results"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'accuracy': 85.61359118019158,\n",
              " 'f1': 0.85598891622568,\n",
              " 'precision': 0.8560188381856575,\n",
              " 'recall': 0.8561359118019157}"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MZAs9cowmTNp"
      },
      "source": [
        "### Model 7: TF Hub Pretrained USE but with 10% of training data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sGgLpoKQmQBc",
        "outputId": "d40c67fd-993b-46e1-e761-c3379f80493a"
      },
      "source": [
        "# Making a better dataset split (no data leakage)\n",
        "train_10_percent_split = int(0.1 * len(train_sentences))\n",
        "train_sentences_10_percent = train_sentences[:train_10_percent_split]\n",
        "train_labels_10_percent = train_labels[:train_10_percent_split]\n",
        "len(train_labels_10_percent)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "4979"
            ]
          },
          "metadata": {},
          "execution_count": 99
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xP5ntZhOmdI2",
        "outputId": "678b8f7b-9f68-44b3-ad18-064c9b38ef2e"
      },
      "source": [
        "# Let's build a model the same as model_6\n",
        "model_7 = tf.keras.models.clone_model(model_6)\n",
        "\n",
        "# Compile model\n",
        "model_7.compile(loss=\"binary_crossentropy\",\n",
        "                optimizer=tf.keras.optimizers.Adam(),\n",
        "                metrics=[\"accuracy\"])\n",
        "\n",
        "# Get a summary (will be same as model_6)\n",
        "model_7.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_6_USE\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "USE (KerasLayer)             (None, 512)               256797824 \n",
            "_________________________________________________________________\n",
            "dense_8 (Dense)              (None, 64)                32832     \n",
            "_________________________________________________________________\n",
            "output_layer (Dense)         (None, 1)                 65        \n",
            "=================================================================\n",
            "Total params: 256,830,721\n",
            "Trainable params: 32,897\n",
            "Non-trainable params: 256,797,824\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xNZxza61ml-g",
        "outputId": "6e586020-3b5d-4272-b463-dac633c63ba1"
      },
      "source": [
        "# Fit the model to the 10% training data subsets\n",
        "model_7_history = model_7.fit(train_sentences_10_percent,\n",
        "                              train_labels_10_percent,\n",
        "                              epochs=5,\n",
        "                              validation_data=(val_sentences, val_labels),\n",
        "                              callbacks=[create_tensorboard_callback(SAVE_DIR,\n",
        "                                                                     \"tf_hub_sentence_encoder_10_percent_correct_split\")])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving TensorBoard log files to: model_logs/tf_hub_sentence_encoder_10_percent_correct_split/20210909-065845\n",
            "Epoch 1/5\n",
            "156/156 [==============================] - 10s 49ms/step - loss: 0.6042 - accuracy: 0.6917 - val_loss: 0.5101 - val_accuracy: 0.7622\n",
            "Epoch 2/5\n",
            "156/156 [==============================] - 8s 51ms/step - loss: 0.4706 - accuracy: 0.7799 - val_loss: 0.4715 - val_accuracy: 0.7764\n",
            "Epoch 3/5\n",
            "156/156 [==============================] - 5s 34ms/step - loss: 0.4374 - accuracy: 0.7925 - val_loss: 0.4633 - val_accuracy: 0.7770\n",
            "Epoch 4/5\n",
            "156/156 [==============================] - 5s 34ms/step - loss: 0.4206 - accuracy: 0.8010 - val_loss: 0.4596 - val_accuracy: 0.7781\n",
            "Epoch 5/5\n",
            "156/156 [==============================] - 5s 34ms/step - loss: 0.4092 - accuracy: 0.8056 - val_loss: 0.4566 - val_accuracy: 0.7773\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HBEF7QMJmo1T"
      },
      "source": [
        "# Make predictions with the model trained on 10% of the data\n",
        "model_7_pred_probs = model_7.predict(val_sentences)\n",
        "model_7_pred_probs[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YnGxYK0emqlg"
      },
      "source": [
        "# Turns pred probs into labels\n",
        "model_7_preds = tf.squeeze(tf.round(model_7_pred_probs))\n",
        "model_7_preds[:10]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ts0RbNskmq66"
      },
      "source": [
        "# Evaluate model 7 predictions\n",
        "model_7_results = calculate_results(y_true=val_labels,\n",
        "                                    y_pred=model_7_preds)\n",
        "model_7_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p8CgaGRzmt8Z"
      },
      "source": [
        "## Comparing the performance of each of our models"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ixfnbc3Rmv_L"
      },
      "source": [
        "# Combine modle results into a DataFrame\n",
        "all_model_results = pd.DataFrame({\"baseline\": baseline_results,\n",
        "                                  \"1_simple_dense\": model_1_results,\n",
        "                                  \"2_lstm\":model_2_results,\n",
        "                                  \"3_gru\":model_3_results,\n",
        "                                  \"4_bidirectional\":model_4_results,\n",
        "                                  \"5_conv1d\":model_5_results,\n",
        "                                  \"6_tf_hub_use_encoder\":model_6_results,\n",
        "                                  \"7_tf_hub_use_encoder_10_percent\":model_7_results})\n",
        "all_model_results = all_model_results.transpose()\n",
        "all_model_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3tTe9aNm_F8"
      },
      "source": [
        "# Reduce the accuracy to the same scale as other metrics\n",
        "all_model_results[\"accuracy\"] = all_model_results[\"accuracy\"]/100\n",
        "all_model_results"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2SvP9DlYnB-R"
      },
      "source": [
        "# Plot and compare all of the model results\n",
        "all_model_results.plot(kind=\"bar\",\n",
        "                       figsize=(10,7)).legend(bbox_to_anchor=(1.0,1.0))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "11E40gvonIPk",
        "outputId": "32bcec3f-641a-4539-cc36-de7aa515e923"
      },
      "source": [
        "# Sort model results by f1-score\n",
        "all_model_results.sort_values(\"f1\", ascending=False)[\"f1\"].plot(kind=\"bar\", figsize=(10,7))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.axes._subplots.AxesSubplot at 0x7f00f5de7a50>"
            ]
          },
          "metadata": {},
          "execution_count": 102
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qvdAite1nIKK"
      },
      "source": [
        "## Saving and loading a trained model\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J-W3IB9pnIH1"
      },
      "source": [
        "# # Save model 1 to HDF5 format\n",
        "# model_2.save(\"model_2.h5\")\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UswAAXxanH-h"
      },
      "source": [
        "## Predicting on Tweets from the wild"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xt2TTJSvozzf"
      },
      "source": [
        "# Turn Tweet into string\n",
        "daniels_tweet = \"Most Earthquake Damage is Caused by Shaking\""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UAT8z1uko61j"
      },
      "source": [
        "def predict_on_sentence(model, sentence):\n",
        "  \"\"\"\n",
        "  Uses model to make a prediction on sentence.\n",
        "\n",
        "  Returns the sentence, the predicted label and the prediction probability.\n",
        "  \"\"\"\n",
        "  pred_prob = model.predict([sentence])\n",
        "  pred_label = tf.squeeze(tf.round(pred_prob)).numpy()\n",
        "  print(f\"Pred: {pred_label}\", \"(Sarcastic)\" if pred_label > 0 else \"(not Sarcastic)\", f\"Prob: {pred_prob[0][0]}\")\n",
        "  print(f\"Text:\\n{sentence}\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IhuYVPs6o7Og",
        "outputId": "3e6ef9f9-3f93-4ddb-ce17-2eba4104f3ad"
      },
      "source": [
        "# Make a prediction on Tweet from the wild\n",
        "predict_on_sentence(model=model_2, # use the USE model\n",
        "                    sentence=daniels_tweet)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pred: 1.0 (Sarcastic) Prob: 0.9999879598617554\n",
            "Text:\n",
            "Most Earthquake Damage is Caused by Shaking\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p7TtFmoJpM6b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}